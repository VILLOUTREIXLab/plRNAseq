{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install --user --upgrade pip\n",
    "# !python3 -m venv plenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!source plenv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "import argparse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import Memory\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from collections import Counter\n",
    "#from pl_model import pl_SVM, pl_nn_RIC, pl_KNN, pl_ric_light, pl_ultra_light_ric\n",
    "from load_pl_data import load_dataset_partial_label\n",
    "\n",
    "\n",
    "from init_dict import init_dict_0, init_method\n",
    "\n",
    "\n",
    "#from pl_setting import split_partial_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "developpement = False  # debugging\n",
    "device = 'cpu'  #device = 'cuda:0'\n",
    "PATH = os.getcwd()\n",
    "path_file_abs = PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_liste = ['Packer', # C. Elegans\n",
    "                    'Paul',  # Myeloid Progenitor\n",
    "                     'Planaria',  # S. Mediterranea\n",
    "\n",
    "\n",
    "                     'linear','half','binary']\n",
    "dataset = dataset_liste[2]\n",
    "\n",
    "# PARTIAL LABELLING SETTING \n",
    "overlap = 1  #[0,1]\n",
    "p = 0.1 # [0.1, 1.0] in the paper\n",
    "k=2 #[2,4,10]\n",
    "I = 'I0'\n",
    "method_liste = [\n",
    "\n",
    "# ALGO IRL \n",
    "'PB',  # Prototype Based\n",
    "'plSVM',  # Support Vector Machine  \n",
    "'plLR',  # Logistic Regression\n",
    "\n",
    "# Special\n",
    "\n",
    "'plhKNN',  # k Nearest Neighbors\n",
    "\n",
    "# Algo IFR \n",
    "'plRF', # Random Forest\n",
    "'plXGBM', # Extreme Gradient Boosting Method\n",
    "'plkernelSVC', # kernel SVM (real kernel implmentation)\n",
    "'plEMLR',   # LR with algo IFR\n",
    "'plEMSVM', # SVM with algo IFR\n",
    "]\n",
    "\n",
    "method = method_liste[0]\n",
    "linear = False #False #neural network for PB or kernel for SVM\n",
    "indice_network = 2 if linear == False  else 0\n",
    "\n",
    "#HIERARCHY\n",
    "\n",
    "choix_C_liste = ['flat','C']\n",
    "choix_C = choix_C_liste[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7590, 50) 7590\n"
     ]
    }
   ],
   "source": [
    "if dataset in ['linear', 'half', 'binary']:\n",
    "    alpha = 0.1  #0.5\n",
    "    programs = 50\n",
    "    lenght_tree = 8\n",
    "    topology = 'half'\n",
    "    nfactor = 5\n",
    "    p = 200\n",
    "\n",
    "    name_tree = '_' + str(programs) + '_' + str(alpha) + '_nfactor_' + str(nfactor)\n",
    "    path_file = path_file_abs + 'data/datasets/Tree/' + str(topology) + '/' + str(lenght_tree) + '/'\n",
    "    dataset = str(topology) + '_' + str(lenght_tree) + '_' + str(programs) + '_' + str(alpha)\n",
    "\n",
    "    X = np.load(path_file + 'X_Tree' + str(name_tree) + '.npy', allow_pickle=True)\n",
    "    y = np.load(path_file + 'y_Tree' + str(name_tree) + '.npy', allow_pickle=True).tolist()\n",
    "    y = [int(element) for element in y]\n",
    "    mat_dist = np.load(path_file + 'Tree' + str(name_tree) + '_mat_dist.npy')\n",
    "    time = np.load(path_file + 'Tree' + str(name_tree) + '_pseudotime.npy')\n",
    "\n",
    "    C = torch.tensor(mat_dist)\n",
    "    X = np.array(X, 'float')\n",
    "    c = C.shape[0]\n",
    "    y_id = torch.eye(c)\n",
    "    print(dataset)\n",
    "\n",
    "    print(name_tree, X.shape, len(y))\n",
    "\n",
    "if dataset in ['Packer', 'Paul', 'Planaria']:\n",
    "\n",
    "    if dataset == 'Packer':\n",
    "        path_file = PATH + '/data/datasets/' + str(dataset) + '/'\n",
    "        try:\n",
    "            X = np.load(path_file + 'X_pca.npy', allow_pickle=True)\n",
    "            y = np.load(path_file + 'y.npy', allow_pickle=True).tolist()\n",
    "            mat_dist = np.load(path_file + str(dataset) + '_mat_dist.npy')\n",
    "            print('X,y loaded')\n",
    "        except:\n",
    "\n",
    "            df = pd.read_csv(path_file + dataset + '.csv')\n",
    "            X = np.asarray(df)\n",
    "            X = X[:, :-1]\n",
    "            np.save(path_file + 'X', X)\n",
    "            try:\n",
    "                y_names = df['labels'].tolist()\n",
    "            except:\n",
    "                y_names = df['cell_type'].tolist()\n",
    "            names = np.load(path_file + dataset + '/' + dataset + '_names.npy').tolist()\n",
    "            names = sorted(list(set(names)))\n",
    "            y = [names.index(i) for i in y_names]\n",
    "            np.save(path_file + 'y', y)\n",
    "            mat_dist = np.load(path_file + str(dataset) + '_mat_dist.npy')\n",
    "\n",
    "    if dataset == 'Planaria' or dataset == 'Paul':\n",
    "        #\n",
    "        path_file = PATH + '/data/datasets/' + str(dataset) + '/'\n",
    "        X = np.load(path_file + 'sample/X.npy', allow_pickle=True)\n",
    "        y = np.load(path_file + 'sample/y.npy', allow_pickle=True).tolist()\n",
    "\n",
    "        mat_dist = np.load(path_file + str(dataset) + '_mat_dist.npy')\n",
    "        # except :\n",
    "        #     path_file = os.getcwd()+'/data/datasets/'+str(dataset)+'/'\n",
    "        #     X = np.load(path_file+'sample/X.npy', allow_pickle=True)\n",
    "        #     y= np.load(path_file+'sample/y.npy', allow_pickle=True).tolist()\n",
    "\n",
    "        #     mat_dist = np.load(path_file + str(dataset)+'_mat_dist.npy')\n",
    "\n",
    "        if dataset == 'Paul':\n",
    "            X, y = X[:-1], y[:-1]\n",
    "\n",
    "    C = torch.Tensor(mat_dist)\n",
    "    X = np.vstack(X).astype(np.float64)\n",
    "    print(X.shape, len(y))\n",
    "    #X= torch.FloatTensor(X)\n",
    "    c = C.shape[0]\n",
    "\n",
    "mat_C = C if choix_C == 'C' else torch.ones((c, c)) - torch.eye(c)\n",
    "C, c, X_train_s, X_train_ws, y_train_s, y_train_ws, \\\n",
    "    y_train_s_prior, y_train_ws_prior, X_test_s, X_test_ws, \\\n",
    "    y_test_s, y_test_ws, y_test_s_prior, y_test_ws_prior \\\n",
    "    = load_dataset_partial_label(PATH=PATH,\n",
    "                                 dataset=dataset,\n",
    "                                 overlap=overlap,\n",
    "                                 I=I,\n",
    "                                 t=0,\n",
    "                                 sub_proportion=p,\n",
    "                                 k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_0, model = init_dict_0(method=method, indice_network=indice_network, dim_int=X_train_s.size(1), c=c, mat_C=mat_C, C=C, device=device,  developpement=developpement)\n",
    "\n",
    "grid = model.tiny_param_grid()  #  spectific parameters which require gridsearch\n",
    "\n",
    "for (keys, values) in grid.items():\n",
    "    dict_0[keys] = random.choice(values)\n",
    "\n",
    "\n",
    "model = init_method(method=method, dict_entry=dict_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T23:12:44.989833134Z",
     "start_time": "2023-07-24T23:12:44.947274447Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pl_model.pl_nn_prototybe_based at 0x7f575f117f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('FIT')\n",
    "model.fit(X_train=torch.cat((X_train_s, X_train_ws), dim=0),\n",
    "          y_train=[[yi] for yi in y_train_s] + y_train_ws_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED TEST\n",
      "dataset : Planaria , overlap :  1 , k :  2   p :  0.1  I :  I0\n",
      "Method :  PB  linear :  False\n",
      "supervised test set accuracy :  0.8228252194732641\n",
      "partial label test set accuracy :  0.8523543495610535\n",
      "partial label test set accuracy with prior :  0.9856344772545889\n"
     ]
    }
   ],
   "source": [
    "print('PRED TEST')\n",
    "pred_train_s = model.predict(X=X_train_s, y_prior=None)\n",
    "pred_train_s_prior = model.predict(X=X_train_s, y_prior=y_train_s_prior)\n",
    "pred_train_ws = model.predict(X=X_train_ws, y_prior=None)\n",
    "pred_train_ws_prior_s = model.predict(X=X_train_ws, y_prior=y_train_ws_prior)\n",
    "\n",
    "pred_test_s = model.predict(X=X_test_s, y_prior=None)\n",
    "pred_test_s_prior = model.predict(X=X_test_s, y_prior=y_test_s_prior)\n",
    "pred_test_ws = model.predict(X=X_test_ws, y_prior=None)\n",
    "pred_test_ws_prior_s = model.predict(X=X_test_ws, y_prior=y_test_ws_prior)\n",
    "\n",
    "performance = [model.score(y_test=y_train_s, y_pred=pred_train_s),\n",
    "               model.score(y_test=y_train_s, y_pred=pred_train_s_prior),\n",
    "               model.score(y_test=y_train_ws, y_pred=pred_train_ws),\n",
    "               model.score(y_test=y_train_ws, y_pred=pred_train_ws_prior_s),\n",
    "               model.score(y_test=y_test_s, y_pred=pred_test_s),\n",
    "               model.score(y_test=y_test_s, y_pred=pred_test_s_prior),\n",
    "               model.score(y_test=y_test_ws, y_pred=pred_test_ws),\n",
    "               model.score(y_test=y_test_ws, y_pred=pred_test_ws_prior_s),\n",
    "\n",
    "               model.error(y_test=y_train_s, y_pred=pred_train_s, C=model.C_score),\n",
    "               model.error(y_test=y_train_s, y_pred=pred_train_s_prior, C=model.C_score),\n",
    "               model.error(y_test=y_train_ws, y_pred=pred_train_ws, C=model.C_score),\n",
    "               model.error(y_test=y_train_ws, y_pred=pred_train_ws_prior_s, C=model.C_score),\n",
    "               model.error(y_test=y_test_s, y_pred=pred_test_s, C=model.C_score),\n",
    "               model.error(y_test=y_test_s, y_pred=pred_test_s_prior, C=model.C_score),\n",
    "               model.error(y_test=y_test_ws, y_pred=pred_test_ws, C=model.C_score),\n",
    "               model.error(y_test=y_test_ws, y_pred=pred_test_ws_prior_s, C=model.C_score),\n",
    "\n",
    "               ]\n",
    "\n",
    "print('dataset :', dataset, ', overlap : ', overlap, ', k : ', k, '  p : ', p,' I : ', I,)\n",
    "print('Method : ', method, ' linear : ', linear)\n",
    "print('supervised test set accuracy : ', performance[4])\n",
    "print('partial label test set accuracy : ', performance[6])\n",
    "print('partial label test set accuracy with prior : ', performance[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
